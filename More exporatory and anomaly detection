# Model1 
     library("tsoutliers")
     require(tsoutliers) 
     library(TTR)
     library(tseries)

#Defining variables
      y<- h$cpu_usage
     d.y <- diff(y)
     t <- h$time

## Descriptive statistics and plotting of cpu usage
     summary(y)   
##   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##-0.0377  0.4326  0.5001  0.5003  0.5677  1.0350 
##suitably lagged and iterated differences
     summary(d.y)  
# plot(t,y)  ## it working loooong time, but apperently it will come up, not recomend to us it
# plot(d.y)

## Dickey Fuller test for variable  shows the data is stationary, p value is significant
## and we can accept Ho hypotesys, so the dta actualy normaly distributed
a     df.test(y, alternative = "stationary", k=0)
#	Augmented Dickey-Fuller Test

 #data:  y
#Dickey-Fuller = -7821, Lag order = 0, p-value = 0.01
#alternative hypothesis: stationary

#Warning message:
#  In adf.test(y, alternative = "stationary", k = 0) :
#  p-value smaller than printed p-value

     adf.test(y, alternative = "explosive", k=0)

#Augmented Dickey-Fuller Test

#data:  y
#Dickey-Fuller = -7821, Lag order = 0, p-value = 0.99
#alternative hypothesis: explosive

#Warning message:
#  In adf.test(y, alternative = "explosive", k = 0) :
#    p-value smaller than printed p-value

     summary(lm(h$cpu_usage~h$time))
#Call:
#  lm(formula = h$cpu_usage ~ h$time)

#Residuals:
#  Min       1Q   Median       3Q      Max 
#-0.53802 -0.06769 -0.00018  0.06739  0.53437 

#Coefficients:
#  Estimate Std. Error t value Pr(>|t|)    
#(Intercept)  5.022e-01  1.096e-03 458.333   <2e-16 ***
#  h$time      -1.262e-12  7.270e-13  -1.736   0.0826 .  
---
##  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 0.1004 on 61176885 degrees of freedom
#Multiple R-squared:  4.926e-08,	Adjusted R-squared:  3.291e-08 
#F-statistic: 3.013 on 1 and 61176885 DF,  p-value: 0.08258

     adf.test(d.y, k=0)   ## we have lag=0 in ADF test
#Augmented Dickey-Fuller Test

#data:  d.y
#Dickey-Fuller = -13550, Lag order = 0, p-value = 0.01
#alternative hypothesis: stationary

#Warning message:
# In adf.test(d.y, k = 0) : p-value smaller than printed p-value
     adf.test(d.y)         ## we have lag = 36 with and let use use d.y

##ACF ( autocorrelationfunction)and PACF (partion autocorrelation function)
     acf(y)   ## Plot_1 We see that the series is stationary enough to do any kind of time 
##series modelling.   (residual ac per units)
     pacf(y)   # correlation is  not significant coz it very short Lags
     acf(d.y)   ## stationary
     pacf(d.y)  ## dfferents PACF is kinda significant, wich said about shorl tail  
## the autocorrelations at lags 2 and above are merely due to the 
##propagation of the autocorrelation at lag 1. This is confirmed by the PACF plot:


#Arima (1,0,0 PACF)
     arima(y)
     arima(y, order = c(1,0,0))
     arima(y, order = c(2,0,0))
     arima(y, order = c(0,0,1))
     arima(y, order = c(1,0,1))

     arima(d.y, order = c(1,0,0))
     arima(d.y, order = c(0,0,1))
     arima(d.y, order = c(1,0,1))
     arima(d.y, order = c(1,0,3))

     boxplot(y~cycle(y), horizontal = T)    ## shows there are outliers here
     plot(h)  
     abline(reg=lm(y~time(y)))

     arima.h1 <- arima.sim(model = list(y,x), n = 120)
     summary(arima.h1)
     h1.ts <- ts(h1)
     h1.ts
     plot(h1.ts)  
##  implement with all dataset too long time to processsing....  never end
     s <- ts(h[,2], start = 1476400427, end= 1537577313, frequency = 1 )
     summary(s)
     s1 <- ts(h1, start = 1476400427, end= 1537577313, frequency = 1 )
     ds <- (DS = decompose(s1))
     ds
     s1
locate.outliers(s, pars, cval = 3.5, types = c("AO", "LS", "TC"),
                delta = 0.7, n.start = 50)

-----
  ##  auto outliers with arima  
  arima.fo<- arima(y, order = c(1, 1, 0), seasonal = list(order = c(2, 0, 2)))
resid <- residuals(arima.fo)
pars <- coefs2poly(arima.fo)
outliers2 <- locate.outliers(resid, pars)
dim(outliers2)
plot(outliers2)
summary(outliers2) ##  result auto outliers 

##Prediction with arima
library(fracdiff)
fit.arima <-arima(y, order = c(1, 1, 1), seasonal = list(order = c(2, 0, 2)))
summary(fit.arima)
plot(forecast(fit.arima,h=20))

fitAr <- forecast::auto.arima(x = y, allowdrift = FALSE, ic = "bic")
summary(fitAr)
 
